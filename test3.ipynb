{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a0742da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 1: Imports + Config ===\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.pipeline import Pipeline as SkPipeline\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# -------------------------\n",
    "# Config\n",
    "# -------------------------\n",
    "DATA_DIR = Path(\"datasets\")\n",
    "MODULE = \"BBB\"\n",
    "PRESENTATIONS = [\"2013B\", \"2013J\"]\n",
    "\n",
    "# Sinh nhiều \"mốc quan sát\" để tạo dataset dạng time-slicing\n",
    "CUTOFFS = [3, 5, 7, 10, 14, 21, 30, 45, 60, 90, 120, 150, 180]\n",
    "\n",
    "WINDOW_DAYS = 14       # cửa sổ feature nhìn lại 14 ngày\n",
    "HALF_WINDOW = 7        # chia 14 ngày thành 2 nửa: 0-7 và 8-14\n",
    "HORIZON = 14           # dự đoán vắng trong 14 ngày tương lai (HƯỚNG 1)\n",
    "VAR_THRESH = 0.0\n",
    "\n",
    "MODEL_PATH = \"short_term_inactive_next14days.pkl\"\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format=\"[%(asctime)s] %(levelname)s - %(message)s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "85fd9df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 2: Load raw OULAD ===\n",
    "def load_raw(data_dir: Path) -> Dict[str, pd.DataFrame]:\n",
    "    return {\n",
    "        \"student_info\": pd.read_csv(data_dir / \"studentInfo.csv\"),\n",
    "        \"student_reg\": pd.read_csv(data_dir / \"studentRegistration.csv\"),\n",
    "        \"student_vle\": pd.read_csv(data_dir / \"studentVle.csv\"),\n",
    "    }\n",
    "\n",
    "\n",
    "def prepare_students(raw: Dict[str, pd.DataFrame], module: str, presentations: List[str]):\n",
    "    reg_mod = raw[\"student_reg\"][\n",
    "        (raw[\"student_reg\"][\"code_module\"] == module)\n",
    "        & (raw[\"student_reg\"][\"code_presentation\"].isin(presentations))\n",
    "    ].copy()\n",
    "\n",
    "    reg_lookup = reg_mod[[\"id_student\", \"date_registration\"]].drop_duplicates()\n",
    "\n",
    "    students = raw[\"student_info\"][\n",
    "        (raw[\"student_info\"][\"code_module\"] == module)\n",
    "        & (raw[\"student_info\"][\"code_presentation\"].isin(presentations))\n",
    "        & (raw[\"student_info\"][\"id_student\"].isin(reg_lookup[\"id_student\"]))\n",
    "    ].copy()\n",
    "\n",
    "    vle_mod = raw[\"student_vle\"][\n",
    "        (raw[\"student_vle\"][\"code_module\"] == module)\n",
    "        & (raw[\"student_vle\"][\"code_presentation\"].isin(presentations))\n",
    "    ].merge(reg_lookup, on=\"id_student\", how=\"inner\")\n",
    "\n",
    "    # relative day since registration (handles late registration)\n",
    "    vle_mod[\"days_since_reg\"] = vle_mod[\"date\"] - vle_mod[\"date_registration\"]\n",
    "\n",
    "    # keep valid relative days\n",
    "    vle_mod = vle_mod[vle_mod[\"days_since_reg\"].notna()].copy()\n",
    "    vle_mod = vle_mod[vle_mod[\"days_since_reg\"] >= 0].copy()\n",
    "\n",
    "    logging.info(\"So hoc vien hop le: %d\", students[\"id_student\"].nunique())\n",
    "    logging.info(\"So ban ghi VLE: %d\", len(vle_mod))\n",
    "    return students, vle_mod\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ea414842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 3: Helpers ===\n",
    "def compute_inactivity_streak(days_list: List[int], start_day: int, end_day: int) -> int:\n",
    "    if not days_list:\n",
    "        return end_day - start_day + 1\n",
    "    active = set(days_list)\n",
    "    streak, d = 0, end_day\n",
    "    while d >= start_day and d not in active:\n",
    "        streak += 1\n",
    "        d -= 1\n",
    "    return streak\n",
    "\n",
    "\n",
    "def build_short_term_label(vle_mod: pd.DataFrame, cutoff: int, horizon: int = HORIZON) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    y_short = 1 if NO activity in (cutoff+1 .. cutoff+horizon)\n",
    "    \"\"\"\n",
    "    future = vle_mod[(vle_mod[\"days_since_reg\"] > cutoff) & (vle_mod[\"days_since_reg\"] <= cutoff + horizon)]\n",
    "    has_future = future.groupby(\"id_student\").size().gt(0).astype(int).reset_index(name=\"has_future_activity\")\n",
    "    has_future[\"y_short\"] = (has_future[\"has_future_activity\"] == 0).astype(int)  # always 0 here; we use fillna(1) later\n",
    "    return has_future[[\"id_student\", \"y_short\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ee092a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 4: Build features + label ===\n",
    "def build_features_short_term(\n",
    "    students: pd.DataFrame,\n",
    "    vle_mod: pd.DataFrame,\n",
    "    cutoffs: List[int],\n",
    "    window_days: int = WINDOW_DAYS,\n",
    "    half_window: int = HALF_WINDOW,\n",
    "    horizon: int = HORIZON,\n",
    ") -> Tuple[pd.DataFrame, List[str]]:\n",
    "\n",
    "    student_ids = students[\"id_student\"].unique()\n",
    "    augmented = []\n",
    "\n",
    "    for cutoff in cutoffs:\n",
    "        w_start = max(0, cutoff - (window_days - 1))\n",
    "        w_end = cutoff\n",
    "\n",
    "        # logs up to cutoff\n",
    "        vle_cum = vle_mod[vle_mod[\"days_since_reg\"] <= cutoff].copy()\n",
    "        vle_win = vle_cum[vle_cum[\"days_since_reg\"] >= w_start].copy()\n",
    "\n",
    "        # ---- base + label (IMPORTANT: do NOT filter out inactive students) ----\n",
    "        base = pd.DataFrame({\"id_student\": student_ids})\n",
    "        base[\"days_elapsed_since_reg\"] = cutoff  # so it becomes a feature too\n",
    "\n",
    "        label_df = build_short_term_label(vle_mod, cutoff, horizon=horizon)\n",
    "        merged = base.merge(label_df, on=\"id_student\", how=\"left\")\n",
    "        # If student not in label_df => NO activity in future => y_short=1 (inactive)\n",
    "        merged[\"y_short\"] = merged[\"y_short\"].fillna(1).astype(int)\n",
    "\n",
    "        # ---- cumulative agg ----\n",
    "        cum_agg = (\n",
    "            vle_cum.groupby(\"id_student\")\n",
    "            .agg(\n",
    "                total_clicks=(\"sum_click\", \"sum\"),\n",
    "                active_days_total=(\"days_since_reg\", \"nunique\"),\n",
    "                last_active=(\"days_since_reg\", \"max\"),\n",
    "            )\n",
    "            .reset_index()\n",
    "        )\n",
    "        cum_agg[\"clicks_per_day_total\"] = cum_agg[\"total_clicks\"] / max(cutoff, 1)\n",
    "        cum_agg[\"active_ratio_total\"] = cum_agg[\"active_days_total\"] / max(cutoff, 1)\n",
    "        cum_agg[\"days_since_last_active\"] = cutoff - cum_agg[\"last_active\"]\n",
    "        cum_agg[\"avg_clicks_per_active_day_total\"] = (\n",
    "            cum_agg[\"total_clicks\"] / cum_agg[\"active_days_total\"].replace(0, np.nan)\n",
    "        ).fillna(0)\n",
    "\n",
    "        # ---- window 14 agg ----\n",
    "        win_agg = (\n",
    "            vle_win.groupby(\"id_student\")\n",
    "            .agg(\n",
    "                clicks_last_14_days=(\"sum_click\", \"sum\"),\n",
    "                active_days_14=(\"days_since_reg\", \"nunique\")\n",
    "            )\n",
    "            .reset_index()\n",
    "        )\n",
    "        win_agg[\"clicks_per_day_14\"] = win_agg[\"clicks_last_14_days\"] / window_days\n",
    "        win_agg[\"active_ratio_14\"] = win_agg[\"active_days_14\"] / window_days\n",
    "\n",
    "        # split 14-day window\n",
    "        first_end = min(w_end, w_start + (half_window - 1))\n",
    "        second_start = min(w_end, first_end + 1)\n",
    "\n",
    "        clicks_0_7 = (\n",
    "            vle_win[(vle_win[\"days_since_reg\"] >= w_start) & (vle_win[\"days_since_reg\"] <= first_end)]\n",
    "            .groupby(\"id_student\")[\"sum_click\"].sum().reset_index(name=\"clicks_0_7\")\n",
    "        )\n",
    "        clicks_8_14 = (\n",
    "            vle_win[(vle_win[\"days_since_reg\"] >= second_start) & (vle_win[\"days_since_reg\"] <= w_end)]\n",
    "            .groupby(\"id_student\")[\"sum_click\"].sum().reset_index(name=\"clicks_8_14\")\n",
    "        )\n",
    "\n",
    "        clicks_last_7 = (\n",
    "            vle_cum[vle_cum[\"days_since_reg\"] > (cutoff - 7)]\n",
    "            .groupby(\"id_student\")[\"sum_click\"].sum().reset_index(name=\"clicks_last_7_days\")\n",
    "        )\n",
    "\n",
    "        # inactivity streak in last 14 days\n",
    "        days_list = (\n",
    "            vle_win.groupby(\"id_student\")[\"days_since_reg\"]\n",
    "            .apply(lambda x: sorted(x.unique()))\n",
    "            .reset_index()\n",
    "            .rename(columns={\"days_since_reg\": \"active_days_list\"})\n",
    "        )\n",
    "        days_list[\"inactivity_streak_14\"] = days_list[\"active_days_list\"].apply(\n",
    "            lambda lst: compute_inactivity_streak(lst, w_start, w_end)\n",
    "        )\n",
    "        streak = days_list[[\"id_student\", \"inactivity_streak_14\"]]\n",
    "\n",
    "        # ---- merge features ----\n",
    "        merged = merged.merge(cum_agg, on=\"id_student\", how=\"left\")\n",
    "        merged = merged.merge(win_agg, on=\"id_student\", how=\"left\")\n",
    "        merged = merged.merge(clicks_0_7, on=\"id_student\", how=\"left\")\n",
    "        merged = merged.merge(clicks_8_14, on=\"id_student\", how=\"left\")\n",
    "        merged = merged.merge(clicks_last_7, on=\"id_student\", how=\"left\")\n",
    "        merged = merged.merge(streak, on=\"id_student\", how=\"left\")\n",
    "\n",
    "        # fill missing -> 0\n",
    "        fill0 = [\n",
    "            \"total_clicks\",\n",
    "            \"active_days_total\",\n",
    "            \"last_active\",\n",
    "            \"clicks_per_day_total\",\n",
    "            \"active_ratio_total\",\n",
    "            \"days_since_last_active\",\n",
    "            \"avg_clicks_per_active_day_total\",\n",
    "            \"clicks_last_14_days\",\n",
    "            \"active_days_14\",\n",
    "            \"clicks_per_day_14\",\n",
    "            \"active_ratio_14\",\n",
    "            \"clicks_last_7_days\",\n",
    "            \"clicks_0_7\",\n",
    "            \"clicks_8_14\",\n",
    "            \"inactivity_streak_14\",\n",
    "        ]\n",
    "        for col in fill0:\n",
    "            if col in merged.columns:\n",
    "                merged[col] = merged[col].fillna(0)\n",
    "\n",
    "        merged[\"trend_click_14\"] = merged[\"clicks_8_14\"] - merged[\"clicks_0_7\"]\n",
    "        merged[\"ratio_click_14\"] = (merged[\"clicks_8_14\"] + 1) / (merged[\"clicks_0_7\"] + 1)\n",
    "\n",
    "        augmented.append(merged)\n",
    "\n",
    "    final_df = pd.concat(augmented, ignore_index=True)\n",
    "\n",
    "    feature_cols = [\n",
    "        \"days_elapsed_since_reg\",\n",
    "        \"clicks_per_day_total\",\n",
    "        \"active_ratio_total\",\n",
    "        \"avg_clicks_per_active_day_total\",\n",
    "        \"days_since_last_active\",\n",
    "        \"clicks_last_14_days\",\n",
    "        \"active_days_14\",\n",
    "        \"clicks_per_day_14\",\n",
    "        \"active_ratio_14\",\n",
    "        \"clicks_last_7_days\",\n",
    "        \"clicks_0_7\",\n",
    "        \"clicks_8_14\",\n",
    "        \"trend_click_14\",\n",
    "        \"ratio_click_14\",\n",
    "        \"inactivity_streak_14\",\n",
    "    ]\n",
    "    return final_df, feature_cols\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bd4135fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 5: Pipelines + Models ===\n",
    "def make_eval_pipe(model):\n",
    "    return ImbPipeline([\n",
    "        (\"variance_threshold\", VarianceThreshold(VAR_THRESH)),\n",
    "        (\"smote\", SMOTE()),\n",
    "        (\"power_transformer\", PowerTransformer()),\n",
    "        (\"classifier\", model),\n",
    "    ])\n",
    "\n",
    "def make_prod_pipe(model):\n",
    "    return SkPipeline([\n",
    "        (\"variance_threshold\", VarianceThreshold(VAR_THRESH)),\n",
    "        (\"power_transformer\", PowerTransformer()),\n",
    "        (\"classifier\", model),\n",
    "    ])\n",
    "\n",
    "MODELS = {\n",
    "    \"LogisticRegression\": LogisticRegression(\n",
    "        penalty=\"l2\",\n",
    "        solver=\"lbfgs\",\n",
    "        max_iter=2000,\n",
    "        class_weight=\"balanced\",\n",
    "        random_state=42\n",
    "    ),\n",
    "    \"RandomForest\": RandomForestClassifier(\n",
    "        n_estimators=400,\n",
    "        max_depth=14,\n",
    "        min_samples_split=10,\n",
    "        min_samples_leaf=4,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        class_weight=\"balanced\"\n",
    "    ),\n",
    "    \"GradientBoosting\": GradientBoostingClassifier(\n",
    "        learning_rate=0.05,\n",
    "        max_depth=3,\n",
    "        min_samples_leaf=30,\n",
    "        min_samples_split=20,\n",
    "        n_estimators=200,\n",
    "        random_state=42\n",
    "    ),\n",
    "    \"MLP\": MLPClassifier(\n",
    "        hidden_layer_sizes=(128,),\n",
    "        max_iter=1200,\n",
    "        early_stopping=True,\n",
    "        random_state=42\n",
    "    )\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dd016fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-12-28 02:17:24,825] INFO - So hoc vien hop le: 3960\n",
      "[2025-12-28 02:17:24,840] INFO - So ban ghi VLE: 864034\n",
      "[2025-12-28 02:17:25,920] INFO - Train samples: 51480\n",
      "[2025-12-28 02:17:25,920] INFO - Positive rate (vang_14days): 63.21%\n",
      "/home/trong-viet/Desktop/lms/engtastic_ai/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/trong-viet/Desktop/lms/engtastic_ai/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/trong-viet/Desktop/lms/engtastic_ai/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/trong-viet/Desktop/lms/engtastic_ai/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/trong-viet/Desktop/lms/engtastic_ai/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Hiệu năng trung bình (sort theo F1) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>mean_accuracy</th>\n",
       "      <th>mean_f1</th>\n",
       "      <th>mean_recall_pos(vang)</th>\n",
       "      <th>mean_specificity</th>\n",
       "      <th>mean_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.849903</td>\n",
       "      <td>0.886685</td>\n",
       "      <td>0.929256</td>\n",
       "      <td>0.713508</td>\n",
       "      <td>0.861538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.846911</td>\n",
       "      <td>0.885287</td>\n",
       "      <td>0.934803</td>\n",
       "      <td>0.695797</td>\n",
       "      <td>0.835115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>0.848524</td>\n",
       "      <td>0.885129</td>\n",
       "      <td>0.923474</td>\n",
       "      <td>0.719677</td>\n",
       "      <td>0.862372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MLP</td>\n",
       "      <td>0.845901</td>\n",
       "      <td>0.883982</td>\n",
       "      <td>0.928982</td>\n",
       "      <td>0.703107</td>\n",
       "      <td>0.852471</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                model  mean_accuracy   mean_f1  mean_recall_pos(vang)  \\\n",
       "1        RandomForest       0.849903  0.886685               0.929256   \n",
       "0  LogisticRegression       0.846911  0.885287               0.934803   \n",
       "2    GradientBoosting       0.848524  0.885129               0.923474   \n",
       "3                 MLP       0.845901  0.883982               0.928982   \n",
       "\n",
       "   mean_specificity  mean_auc  \n",
       "1          0.713508  0.861538  \n",
       "0          0.695797  0.835115  \n",
       "2          0.719677  0.862372  \n",
       "3          0.703107  0.852471  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved model to: short_term_inactive_next14days.pkl (best=RandomForest)\n"
     ]
    }
   ],
   "source": [
    "# === Cell 6: Train/Eval GroupKFold + Save best ===\n",
    "raw = load_raw(DATA_DIR)\n",
    "students, vle_mod = prepare_students(raw, MODULE, PRESENTATIONS)\n",
    "\n",
    "final_df, feature_cols = build_features_short_term(\n",
    "    students, vle_mod, CUTOFFS,\n",
    "    window_days=WINDOW_DAYS, half_window=HALF_WINDOW, horizon=HORIZON\n",
    ")\n",
    "\n",
    "X = final_df[feature_cols].fillna(0)\n",
    "y = final_df[\"y_short\"].astype(int)     # 1 = vắng 14 ngày tới\n",
    "groups = final_df[\"id_student\"]\n",
    "\n",
    "logging.info(\"Train samples: %d\", len(final_df))\n",
    "logging.info(\"Positive rate (vang_14days): %.2f%%\", 100 * y.mean())\n",
    "\n",
    "gkf = GroupKFold(n_splits=5)\n",
    "summary_rows = []\n",
    "\n",
    "for name, model in MODELS.items():\n",
    "    fold_rows = []\n",
    "    for tr_idx, te_idx in gkf.split(X, y, groups):\n",
    "        X_tr, X_te = X.iloc[tr_idx], X.iloc[te_idx]\n",
    "        y_tr, y_te = y.iloc[tr_idx], y.iloc[te_idx]\n",
    "\n",
    "        pipe = make_eval_pipe(model)\n",
    "        pipe.fit(X_tr, y_tr)\n",
    "\n",
    "        y_pred = pipe.predict(X_te)\n",
    "        if hasattr(pipe, \"predict_proba\"):\n",
    "            y_proba = pipe.predict_proba(X_te)[:, 1]\n",
    "            auc = roc_auc_score(y_te, y_proba)\n",
    "        else:\n",
    "            auc = np.nan\n",
    "\n",
    "        tn, fp, fn, tp = confusion_matrix(y_te, y_pred).ravel()\n",
    "        fold_rows.append({\n",
    "            \"model\": name,\n",
    "            \"accuracy\": accuracy_score(y_te, y_pred),\n",
    "            \"f1\": f1_score(y_te, y_pred),\n",
    "            \"recall_pos(vang)\": recall_score(y_te, y_pred),\n",
    "            \"specificity\": tn / (tn + fp + 1e-9),\n",
    "            \"auc\": auc,\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(fold_rows)\n",
    "    summary_rows.append({\n",
    "        \"model\": name,\n",
    "        \"mean_accuracy\": df[\"accuracy\"].mean(),\n",
    "        \"mean_f1\": df[\"f1\"].mean(),\n",
    "        \"mean_recall_pos(vang)\": df[\"recall_pos(vang)\"].mean(),\n",
    "        \"mean_specificity\": df[\"specificity\"].mean(),\n",
    "        \"mean_auc\": df[\"auc\"].mean(),\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_rows).sort_values(\"mean_f1\", ascending=False)\n",
    "print(\"=== Hiệu năng trung bình (sort theo F1) ===\")\n",
    "display(summary_df)\n",
    "\n",
    "best_model_name = summary_df.iloc[0][\"model\"]\n",
    "best_model = MODELS[best_model_name]\n",
    "\n",
    "prod_pipe = make_prod_pipe(best_model)\n",
    "prod_pipe.fit(X, y)\n",
    "\n",
    "joblib.dump({\"pipeline\": prod_pipe, \"feature_cols\": feature_cols}, MODEL_PATH)\n",
    "print(f\"✅ Saved model to: {MODEL_PATH} (best={best_model_name})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a4278103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Dự đoán NGẮN HẠN (vắng >14 ngày tới) cho student_id=1001 ---\n",
      "P(vắng 14 ngày tới): 37.98%\n",
      "Kết luận: ✅ CÓ KHẢ NĂNG VẪN HỌC\n"
     ]
    }
   ],
   "source": [
    "# === Cell 7: Inference (nhập feature JSON) ===\n",
    "bundle = joblib.load(MODEL_PATH)\n",
    "loaded_pipe = bundle[\"pipeline\"]\n",
    "feature_cols = bundle[\"feature_cols\"]\n",
    "\n",
    "# Case cực đoan: 14 ngày gần nhất không có hoạt động\n",
    "student_data = {\n",
    "    \"student_id\": \"1001\",\n",
    "    \"days_elapsed_since_reg\": 40,\n",
    "\n",
    "    \"clicks_per_day_total\": 0.05,\n",
    "    \"active_ratio_total\": 0.05,\n",
    "    \"avg_clicks_per_active_day_total\": 1.0,\n",
    "\n",
    "    \"days_since_last_active\": 9,\n",
    "    \"clicks_last_14_days\": 2,\n",
    "    \"active_days_14\": 1,\n",
    "    \"clicks_per_day_14\": 2/14,\n",
    "    \"active_ratio_14\": 1/14,\n",
    "\n",
    "    \"clicks_last_7_days\": 0,\n",
    "    \"clicks_0_7\": 0,\n",
    "    \"clicks_8_14\": 2,\n",
    "    \"trend_click_14\": 2,\n",
    "    \"ratio_click_14\": 3.0,\n",
    "\n",
    "    \"inactivity_streak_14\": 8\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "input_df = pd.DataFrame([student_data])[feature_cols].fillna(0)\n",
    "\n",
    "proba_vang = loaded_pipe.predict_proba(input_df)[0, 1]\n",
    "pred = loaded_pipe.predict(input_df)[0]\n",
    "\n",
    "print(f\"--- Dự đoán NGẮN HẠN (vắng >14 ngày tới) cho student_id={student_data['student_id']} ---\")\n",
    "print(f\"P(vắng 14 ngày tới): {proba_vang:.2%}\")\n",
    "print(f\"Kết luận: {'⚠️ NGUY CƠ VẮNG' if pred==1 else '✅ CÓ KHẢ NĂNG VẪN HỌC'}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
